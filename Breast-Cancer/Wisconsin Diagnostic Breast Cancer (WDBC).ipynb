{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Diagnostic Breast Cancer (WDBC) Dataset with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am writing the explorative analysis of the dataset using a series of Python (ver.2.7.11) packages that facilitate the access to the data as well as the statistical analysis. In particular, I am using Panda (ver.0.17), scikit-learn (ver.0.17) together with the more common numerical packages available for Python such as numpy and matplotlib. I am also using jupyter notebooks for this type of quick data analysis. I usually save everything into a normal python script after I streamline the major features of the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import urllib\n",
    "from math import sqrt\n",
    "from sklearn import tree\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import StringIO\n",
    "from pydot import graph_from_dot_data as gdot\n",
    "from sklearn.externals.six import StringIO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the attibutes of the dataset can be found on the UCI Machine Learning Repository website (https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names):\n",
    "* radius (mean of distances from center to points on the perimeter)\n",
    "* texture (standard deviation of gray-scale values)\n",
    "* perimeter\n",
    "* area\n",
    "* smoothness (local variation in radius lengths)\n",
    "* compactness (perimeter^2 / area - 1.0)\n",
    "* concavity (severity of concave portions of the contour)\n",
    "* concave points (number of concave portions of the contour)\n",
    "* symmetry \n",
    "* fractal dimension (\"coastline approximation\" - 1)\n",
    " \n",
    "The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# URL for the Wisconsin Diagnostic Breast Cancer (WDBC) (UCI Machine Learning Repository)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "# download the file\n",
    "raw_data = urllib.urlopen(url)\n",
    "# load the file as a numpy matrix\n",
    "attributes = ['id','cancer_type','mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area',\n",
    "       'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
    "       'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "       'radius_error', 'texture_error', 'perimeter_error', 'area_error',\n",
    "       'smoothness_error', 'compactness_error', 'concavity_error',\n",
    "       'concave_points_error', 'symmetry_error', 'fractal_dimension_error',\n",
    "       'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
    "       'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
    "       'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension']\n",
    "bcd =  np.genfromtxt(raw_data, delimiter=',', dtype=None, names= attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# demo numpy matrix to Pandas DataFrame\n",
    "bcdf = pd.DataFrame(data=bcd, columns=attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the dataset in a training set randomly sampled and the remaining 20% will be used to test my prediction model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = bcdf.sample(frac=0.8)\n",
    "test  = bcdf.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manipulate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = train.columns[2:32]\n",
    "X = train.ix[:,2:32]\n",
    "y = train.ix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create decision tree\n",
    "dt_train = tree.DecisionTreeClassifier(max_depth=500, min_samples_leaf=1)\n",
    "dt_train.fit(X,y)\n",
    "tree.export_graphviz(dt_train,feature_names=labels, out_file='tree_train.dot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a png of the tree we can run the following command from terminal:\n",
    "\n",
    "```dot -Tpng tree_train.dot -o tree_train.png```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig:tree_train](tree_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = test.columns[2:32]\n",
    "X = test.ix[:,2:32]\n",
    "y = test.ix[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model with a prediction on the remaining 20% of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predict = dt_train.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's better than a cross-tabulation to test the success rate. We obtain an accuracy of 94.7% of the model on the a the test dataset (114 observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>B</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds    B   M\n",
       "actual        \n",
       "B       71   4\n",
       "M        2  37"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['cancer_type'], test_predict, rownames=['actual'], colnames=['preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create decision tree also on the remaining test dataset. It is not really usefull for the analysis, but it shows how sensitive is the tree shape to the dataset. Which I think it is one of the limitations of the decision tree method partially solved by using Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_test = tree.DecisionTreeClassifier(max_depth=500, min_samples_leaf=1)\n",
    "dt_test.fit(X, y)\n",
    "tree.export_graphviz(dt_test,feature_names=labels, out_file='tree_test.dot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![fig:tree_test](tree_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
