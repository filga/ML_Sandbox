{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisconsin Diagnostic Breast Cancer (WDBC) Dataset with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am writing the explorative analysis of the dataset using a series of Python (ver.2.7.11) packages that facilitate the access to the data as well as the statistical analysis. In particular, I am using Panda (ver.0.17), scikit-learn (ver.0.17) together with the more common numerical packages available for Python such as numpy and matplotlib. I am also using jupyter notebooks for this type of quick data analysis. I usually save everything into a normal python script after I streamline the major features of the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import urllib\n",
    "from math import sqrt\n",
    "from sklearn import tree\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import StringIO\n",
    "from pydot import graph_from_dot_data as gdot\n",
    "from sklearn.externals.six import StringIO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the attibutes of the dataset can be found on the UCI Machine Learning Repository website (https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names):\n",
    "* radius (mean of distances from center to points on the perimeter)\n",
    "* texture (standard deviation of gray-scale values)\n",
    "* perimeter\n",
    "* area\n",
    "* smoothness (local variation in radius lengths)\n",
    "* compactness (perimeter^2 / area - 1.0)\n",
    "* concavity (severity of concave portions of the contour)\n",
    "* concave points (number of concave portions of the contour)\n",
    "* symmetry \n",
    "* fractal dimension (\"coastline approximation\" - 1)\n",
    " \n",
    "The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# URL for the Wisconsin Diagnostic Breast Cancer (WDBC) (UCI Machine Learning Repository)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "# download the file\n",
    "raw_data = urllib.urlopen(url)\n",
    "# load the file as a numpy matrix\n",
    "attributes = ['id','cancer_type','mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area',\n",
    "       'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
    "       'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "       'radius_error', 'texture_error', 'perimeter_error', 'area_error',\n",
    "       'smoothness_error', 'compactness_error', 'concavity_error',\n",
    "       'concave_points_error', 'symmetry_error', 'fractal_dimension_error',\n",
    "       'worst_radius', 'worst_texture', 'worst_perimeter', 'worst_area',\n",
    "       'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
    "       'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension']\n",
    "bcd =  np.genfromtxt(raw_data, delimiter=',', dtype=None, names= attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the numpy array into Pandas DataFrame\n",
    "bcdf = pd.DataFrame(data=bcd, columns=attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the dataset in a training set randomly sampled while the remaining 20% will be used to test the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = bcdf.sample(frac=0.8)\n",
    "test  = bcdf.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by using all the attributes of the dataset to build the decision tree. No feature selection to find a subset of relevant features for use in model construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = train.columns[2:32]\n",
    "X = train.ix[:,2:32]\n",
    "y = train.ix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the decision tree \n",
    "dt_train = tree.DecisionTreeClassifier(max_depth=500, min_samples_leaf=1)\n",
    "dt_train.fit(X,y)\n",
    "tree.export_graphviz(dt_train,feature_names=labels, out_file='tree_train.dot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a png of the tree we can run the following command from terminal:\n",
    "\n",
    "```dot -Tpng tree_train.dot -o tree_train.png```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig:tree_train](tree_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is constructed using all the attributes in the dataset and the Gini impurity to measure the quality of the split. The model tries to predict if a cancer is benign or malignant given a set of carefully measured parameters of the cancer itsels (see list above). In the model above the first split in the tree is given by the *worst perimeter* (from a set of three images of the tumor) with a value of 105.95 as delimiter. The second split in the data is determined by the *worst concave points* for the data with a value of the *worste perimter* less or equal to 105.95 while for the remaining is the *mean concave points* which produces the split. I suppose that *worst*, *mean* and the actual value of the different attributes are actually correlated making some of the quantities partially redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = test.columns[2:32]\n",
    "X = test.ix[:,2:32]\n",
    "y = test.ix[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model with a prediction on the remaining 20% of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predict = dt_train.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's better than a cross-tabulation to test the success rate. We obtain an accuracy of 95.5% of the model on the a the test dataset (112 observations). The true positive rate (sensitivity) is 94.5% while the specificity is 92.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>B</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds    B   M\n",
       "actual        \n",
       "B       69   3\n",
       "M        4  38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['cancer_type'], test_predict, rownames=['actual'], colnames=['preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create decision tree also on the remaining test dataset. It is not really usefull for the analysis, but it shows how sensitive is the tree shape to the dataset. Which I think it is one of the limitations of the decision tree method partially solved by using Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_test = tree.DecisionTreeClassifier(max_depth=500, min_samples_leaf=1)\n",
    "dt_test.fit(X, y)\n",
    "tree.export_graphviz(dt_test,feature_names=labels, out_file='tree_test.dot') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![fig:tree_test](tree_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
